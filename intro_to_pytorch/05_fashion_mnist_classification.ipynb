{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helper functions\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# device\n",
    "device = \"cpu\"\n",
    "\n",
    "# print(torch.__version__)\n",
    "# print(np.__version__)\n",
    "# print(torchvision.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Computer Vision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Computer Vision libraries in PyTorch\n",
    "* `torchvision.datasets` - get datasets and data loading functions for computer vision\n",
    "* `torchvision.models` - get pretrained computer vision models that you can leverage for your own problems\n",
    "* `torchvision.transforms` - functions for manipulating your vision data (images) to be suitable for use with an ML model\n",
    "* `torch.utils.data.Dataset` - Base dataset class for PyTorch\n",
    "* `torch.utils.data.Datalodaer` - Creates a Python iterable over a dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Getting a Dataset\n",
    "\n",
    "* FashionMNIST from `torchvision.datasets`\n",
    "* https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Setup Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # where to download data?\n",
    "    train=True, # do we want the training dataset?\n",
    "    download=True, # do we want to download yes/no?\n",
    "    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data?\n",
    "    target_transform=None # how do we want to transform the labels/targets?\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Brief Overview of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out dataset\n",
    "train_data_len, test_data_len = len(train_data), len(test_data)\n",
    "# print(train_data_len, test_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see first training example\n",
    "image, label = train_data[0]\n",
    "# print(image, label)\n",
    "# print(type(image), type(label))\n",
    "\n",
    "image_size, label_size = image.size(), label\n",
    "image_dtype, label_dtype = image.dtype, type(label)\n",
    "print(image_size, label_size)\n",
    "print(image_dtype, label_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Image Shape: {image.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image Label: {class_names[label]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Become One with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "# print(f\"Image Shape: {image.shape}\")\n",
    "# print(image)\n",
    "# print(image.squeeze().shape)\n",
    "\n",
    "\"\"\"\n",
    "plt.title(class_names[label])\n",
    "plt.imshow(image.squeeze())\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows*cols+1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    # print(random_idx)\n",
    "    img, img_label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[img_label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Prepare DataLoader\n",
    "\n",
    "* DataLoader turns the dataset into a Python iterable\n",
    "* We want to turn the data into batches (mini-batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size is a hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# turn datasets into iterables (batches)\n",
    "# this is a dataloader object\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Interacting with DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape\n",
    "\n",
    "\"\"\"\n",
    "32 data per batch.\n",
    "1 color type (black or white) per data.\n",
    "28 x 28 pixels per data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample\n",
    "# torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "data_img, data_label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "\n",
    "# plot image\n",
    "\"\"\"\n",
    "plt.imshow(data_img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[data_label])\n",
    "plt.axis(False)\n",
    "print(f\"Image Size: {data_img.shape}\")\n",
    "print(f\"Label: {data_label}, Label Size: {data_label.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "# now we have data that is seperated into different batches\n",
    "# time to build model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Build a Baseline Model\n",
    "\n",
    "* Start with baseline model\n",
    "* Improve model through different experiments\n",
    "* Start simply and add complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# get single sample flatten\n",
    "x = train_features_batch[0]\n",
    "# x.shape # torch.Size([1, 28, 28])\n",
    "\n",
    "# flatten sample data\n",
    "output = flatten_model(x)\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x)\n",
    "# print(output)\n",
    "# output.squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 Model for Linear Layers\n",
    "\n",
    "* A linear layer model can only handle 1-dimensional input data\n",
    "* Original Data -> [1, 28, 28]\n",
    "* Flattened Data -> [1, 784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build base model\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(input_shape=784, # 28x28\n",
    "                              hidden_units=10, # hidden layer nodes\n",
    "                              output_shape=len(class_names) # one for every class\n",
    "                              ).to(device)\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if model works\n",
    "dummy_x = torch.rand([1, 1, 28, 28])\n",
    "model_0(dummy_x)\n",
    "print(model_0(dummy_x).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Setup Loss, Optimizer, and Evaluaiton Metrics\n",
    "\n",
    "* Loss function - since we're working with multi-class data, our loss function will be `nn.CrossEntropyLoss()`\n",
    "* Optimizer - SGD, `torch.optim.SGD()`\n",
    "* Evaluation Metric - classification problem w/ balanced dataset, we'll use `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy functions\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"helper_functions.py already exists, skipping download...\")\n",
    "else:\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.1)\n",
    "\n",
    "# setup timer function\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device=None):\n",
    "    \"\"\"\n",
    "    Prints difference between start adn end time.\n",
    "    \"\"\"\n",
    "\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device} : {total_time: .3f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "start_time = timer()\n",
    "for i in range(100):\n",
    "    i += i\n",
    "print(i)\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 Train and Test (linear model)\n",
    "\n",
    "1. Loop through epochs.\n",
    "2. Loop through training batches, perform training steps, calculate the train loss *per batch*.\n",
    "3. Loop through testing batches, perform testing steps, calculate test loss *per batch*.\n",
    "4. Print out what's happening.\n",
    "5. Time it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 3 # small for faster training time\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n------\")\n",
    "\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        y_pred = model_0.forward(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # for every batch accumulate train loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "    \n",
    "    # divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            test_pred = model_0.forward(X)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}%\")\n",
    "\n",
    "train_time_end = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start,\n",
    "                                            end=train_time_end,\n",
    "                                            device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Make Predictions & Get Model Results\n",
    "\n",
    "* want to automate the process of evaluating model (train loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the results of model predicting on data_loader. We can compare the dictionary per model for different models with different hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            # make predictions\n",
    "            y_pred = model.forward(X)\n",
    "\n",
    "            # accumulate loss & acc per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                               y_pred=y_pred.argmax(dim=1))\n",
    "            \n",
    "        # scale loss and acc to find average per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model is created with class\n",
    "            \"model_loss\": loss.item(), \n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# calculate model_0 results on test dataset\n",
    "model_0_results = eval_model(model=model_0,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn)\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Building a Better Model w/ Non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(in_features=hidden_units,\n",
    "            #           out_features=hidden_units),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape),\n",
    "            nn.ReLU()                 \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Functionizing Train & Test Loop\n",
    "\n",
    "* training loop - `train_step()`\n",
    "* testing loop - `test_step()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Automize Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device=device):\n",
    "    \"\"\"\n",
    "    Performs a training with model trying to learn on data_loader.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # put data on target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # make predictions\n",
    "        y_pred = model.forward(X)\n",
    "\n",
    "        # calculate & accumulate loss (wrongness)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss \n",
    "\n",
    "        # calculate & accumulate acc\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # change logits -> prediction labels\n",
    "\n",
    "        # optimize model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of progress\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples.\")\n",
    "    \n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Automize Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device=device):\n",
    "    \"\"\"\n",
    "    Performs a testing loop step with model going over data_loader.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            test_pred = model.forward(X)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Call Train & Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch} \\n-----------\")\n",
    "    \n",
    "    train_step(model=model_1,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    \n",
    "    test_step(model=model_1,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "\n",
    "train_time_end = timer()\n",
    "total_train_time_model_1 = print_train_time(\n",
    "                        start=train_time_start,\n",
    "                        end=train_time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_results = eval_model(model=model_1,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn)\n",
    "\n",
    "print(model_0_results)\n",
    "print(model_1_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
