{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Neural Network Classification with PyTorch\n",
    "\n",
    "Classification is a problem of predicting whether something is one thing or another (there can be multiple options.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# print(torch.__version__)\n",
    "# print(np.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Machine Learning Library : scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.scatter(x=X[:, 0],\\n            y=X[:, 1],\\n            c=y,\\n            cmap=plt.cm.RdYlBu)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# print(sklearn.__version__)\n",
    "# print(pd.__version__)\n",
    "\n",
    "# make 1000 samples\n",
    "n_samples = 1000\n",
    "\n",
    "# create circles\n",
    "X, y = make_circles(n_samples, # data imported from scikit learn\n",
    "                    noise=0.03,\n",
    "                    random_state=42)\n",
    "\n",
    "# print(len(X), len(y))\n",
    "# print(f\"First 5 samples of X:\\n {X[:5]}\")\n",
    "# print(f\"First 5 samples of y:\\n {y[:5]}\")\n",
    "\n",
    "# make dataframe of circle data\n",
    "circles = pd.DataFrame({\"X1\": X[:, 0],\n",
    "                         \"X2\": X[:, 1],\n",
    "                         \"label\": y})\n",
    "\n",
    "circles.head(10)\n",
    "# print(circles.head(10))\n",
    "\n",
    "# graphical visualization\n",
    "\"\"\"\n",
    "plt.scatter(x=X[:, 0],\n",
    "            y=X[:, 1],\n",
    "            c=y,\n",
    "            cmap=plt.cm.RdYlBu)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Check input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape, y.shape)\n",
    "# X is a data in matrix form. y is a scalar (0 or 1)\n",
    "\n",
    "# the given data is numerical values in different forms (vector, matrix, scalar)\n",
    "# not tensors yet!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Turn data into tensors and create train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(X_test) # prints raw numpy data\\nprint(X_train.shape)\\nprint(len(X_train), len(X_test), len(y_train), len(y_test))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check given type (numpy.ndarray)\n",
    "\"\"\"\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "print(X.dtype)\n",
    "print(y.dtype)\n",
    "\"\"\"\n",
    "\n",
    "# change data type to tensor (torch.tensor)\n",
    "X_T = torch.from_numpy(X).type(torch.float)\n",
    "y_T = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "\"\"\"\n",
    "print(\"\")\n",
    "print(type(X_T))\n",
    "print(type(y_T))\n",
    "print(X_T.dtype)\n",
    "print(y_T.dtype)\n",
    "\"\"\"\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_T,\n",
    "                                                    y_T,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=12)\n",
    "\n",
    "\"\"\"\n",
    "print(X_test) # prints raw numpy data\n",
    "print(X_train.shape)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Building a Model\n",
    "\n",
    "Build a model to classify blue and red dots of the circle.\n",
    "\n",
    "To do:\n",
    "1. Construct a model (by subclassing `nn.Module`) <b>= INHERITANCE</b>\n",
    "2. Define a loss function and optimizer\n",
    "3. Create a training a test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup device (later save and run via device)\n",
    "device = \"cpu\" # we don't have cuda (gpu)\n",
    "\n",
    "# subclass (inherit) nn.Module & construct model\n",
    "\n",
    "class CircleModelV0(nn.Module):\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    # linear layer (use in foward method)\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=5)\n",
    "        self.layer_2 = nn.Linear(in_features=5, out_features=1)\n",
    "\n",
    "    # foward method\n",
    "    def forward(self, x):\n",
    "        return self.layer_2(self.layer_1(x))\n",
    "    \n",
    "model_0 = CircleModelV0().to(device)\n",
    "# model_0\n",
    "\n",
    "# use nn.Sequential to simplify model\n",
    "model_seq = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=5),\n",
    "    nn.Linear(in_features=5, out_features=1)\n",
    ").to(device)\n",
    "\n",
    "# model_seq\n",
    "\n",
    "\"\"\"\n",
    "print(model_0)\n",
    "print(model_seq)\n",
    "\"\"\"\n",
    "with torch.inference_mode():\n",
    "    untrained_predictions = model_0(X_test.to(device))\n",
    "# print(untrained_predictions)\n",
    "# print(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Setting up Loss Function & Optimizer\n",
    "\n",
    "1. Loss function measures how *wrong* your model's predictions are.\n",
    "2. Based on the loss function, we minimize the output of the loss function by optimizer (e.g. Adam, SGD)\n",
    "3. We will be using `torch.nn.BECWithLogitsLoss()` for the loss function. (BCE = Binary Cross Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss function\n",
    "\n",
    "# BCEWithLogitsLoss() has sigmoid built-in as activation function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# set optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.1)\n",
    "\n",
    "# print(model_0.state_dict())\n",
    "# print(model_0.parameters())\n",
    "\n",
    "# calculate accuracy\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct/len(y_pred)) * 100\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Train Model\n",
    "\n",
    "1. Forward pass (built-in)\n",
    "2. Calculate loss (BCE)\n",
    "3. Backpropagation\n",
    "4. Optimize (gradient descent)\n",
    "\n",
    "#### 3.1 Convert logits into prediction probabilities\n",
    "\n",
    "Convert **logits** by passing them through activation functions.\n",
    "\n",
    "1. Binary Classification -> `Sigmoid`\n",
    "2. Multiclass Classification -> `Softmax`\n",
    "\n",
    "#### 3.2 Convert prediction probabilities into prediction labels\n",
    "\n",
    "1. Round Probability\n",
    "2. Take Max `argmax()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# simple testing (first five)\n",
    "\n",
    "\"\"\"\n",
    "Whenever making predictions, turn model into eval mode and run inference mode. Turn model back into train mode for training.\n",
    "\"\"\"\n",
    "\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_0(X_test.to(device))[:5]\n",
    "\n",
    "# print(y_logits)\n",
    "# print(y_test[:5])\n",
    "\n",
    "# different form! change logit to y_test form\n",
    "# 3.1 process\n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "# print(y_pred_probs)\n",
    "\n",
    "# round prediction probabilities\n",
    "y_preds = torch.round(y_pred_probs)\n",
    "# print(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Together (logits -> pred probs -> pred labels)\n",
    "y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaurantee reproducibility (not necessary process)\n",
    "torch.manual_seed(11)\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
