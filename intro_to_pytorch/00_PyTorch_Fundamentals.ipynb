{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. PyTorch Fundamentals\n",
    "\n",
    "Resource notebook : https://www.learnpytorch.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check pytorch version via python syntax\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "## Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  7,  3],\n",
       "        [10,  5,  3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "# A matrix only has two dimensions; the row & column\n",
    "matrix = torch.tensor([[7, 7, 3], [10, 5, 3]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  5,  3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "# A tensor has multiple dimensions\n",
    "tensor = torch.tensor([[[1, 2, 3],[4, 5, 6],[7, 8, 9]]])\n",
    "tensor # this goes beyond the row, column axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each dimension corresponds to the number of brackets\n",
    "# the example below calls only one dimension which corresponds to the outer most bracket\n",
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this example calls 2 dimensions\n",
    "# first index has access to the first bracket (first dimension),\n",
    "# and the second index has access to the second bracket which corresponds to the second dimension\n",
    "tensor[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0][1][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7724, 0.5924, 0.9459, 0.5267],\n",
       "        [0.5731, 0.8673, 0.3681, 0.0593],\n",
       "        [0.3788, 0.5710, 0.9077, 0.6445]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_shape = random_tensor.shape\n",
    "r_shape # 3 rows, 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # (height, width, color channels (R, G, B))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim # 3 dimensions!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range()\n",
    "zero_to_ten = torch.arange(0, 10)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_range = torch.arange(start=0, end=1000, step=77)\n",
    "step_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "# generates a tensor that is \"like\" the input which basically has same shape\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "** Note:** Tensor datatypes is one of the 3 most frequent errors in PyTorch & Deep Learning.\n",
    "1. Tensors are not in the right datatype\n",
    "2. Tensors are not in the right shape\n",
    "3. Tensors are not on right device (cpu, gpu etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can change the data type\n",
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert datatype\n",
    "float_32_to_16 = float_32_tensor.type(torch.float16)\n",
    "float_32_to_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplication of tensors with different shapes\n",
    "# some operations will generate an error (not this one)\n",
    "# but should be always aware of type\n",
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from tensors (not to create errors)\n",
    "\n",
    "1. Check tensor data type - tensor.dtype\n",
    "2. Check tensor shape - tensor.shape\n",
    "3. Check tensor device - tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6787, 0.9344, 0.1175, 0.3294],\n",
       "        [0.7809, 0.0809, 0.6458, 0.2735],\n",
       "        [0.1463, 0.0303, 0.5251, 0.4166]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first create tensor variable\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6787, 0.9344, 0.1175, 0.3294],\n",
      "        [0.7809, 0.0809, 0.6458, 0.2735],\n",
      "        [0.1463, 0.0303, 0.5251, 0.4166]])\n",
      "Datatype of Tensor: torch.float32\n",
      "Shape of Tensor: torch.Size([3, 4])\n",
      "Tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# check details of \"some_tensor\"\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of Tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of Tensor: {some_tensor.shape}\")\n",
    "print(f\"Tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor type is: torch.int64\n",
      "tensor([11, 12, 13])\n",
      "tensor([10, 20, 30])\n",
      "tensor([20, 40, 60])\n",
      "tensor([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor and add 10 to it\n",
    "tensor_manip = torch.tensor([1, 2, 3])\n",
    "print(tensor_manip)\n",
    "print(f\"tensor type is: {tensor_manip.dtype}\") # check data type\n",
    "print(tensor_manip + 10) # element addition\n",
    "print(tensor_manip * 10) # element multiplication\n",
    "\n",
    "\n",
    "# PyTorch in-built functions\n",
    "print(torch.mul(tensor_manip, 20))\n",
    "print(torch.add(tensor_manip, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise Multiplication looks like:\n",
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n",
      "Matrix Multiplication result is:\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication vs Element-wise Multiplication\n",
    "\n",
    "# Element-wise Multiplication\n",
    "tensor_ex1 = torch.tensor([1, 2, 3])\n",
    "print(\"Element-wise Multiplication looks like:\")\n",
    "print(tensor_ex1, \"*\", tensor_ex1)\n",
    "print(f\"Equals: {tensor_ex1 * tensor_ex1}\")\n",
    "\n",
    "\n",
    "# Matrix Multiplication\n",
    "tensor_matrix_mul = torch.matmul(tensor_ex1, tensor_ex1)\n",
    "print(\"Matrix Multiplication result is:\")\n",
    "print(tensor_matrix_mul)\n",
    "\n",
    "# although they are both row matrices, the matmul function reads it as column matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: user 1.24 ms, sys: 980 µs, total: 2.22 ms\n",
      "Wall time: 2.89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# the time function has to be at the top of the block\n",
    "# the function operates for the entire block, so it doesn't work if it's located in the middle\n",
    "\n",
    "value = 0\n",
    "for i in range(len(tensor_ex1)):\n",
    "    value += tensor_ex1[i] * tensor_ex1[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 µs, sys: 5 µs, total: 39 µs\n",
      "Wall time: 42 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor_ex1, tensor_ex1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satisfying Matrix Multiplication\n",
    "\n",
    "There are two conditions for a successful matrix multiplication:\n",
    "1. The **inner dimensions** must match:\n",
    "* `@` is equivalent to `torch.matmul`\n",
    "* `(3, 2) @ (3, 2)` doesn't work\n",
    "* `(2, 3) @ (3, 2)` does work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions:**\n",
    "* `(2, 3) @ (3, 2)` -> `(2, 2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9187, 0.2950],\n",
       "        [0.5248, 0.1532]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this generates an shape mismatch error\n",
    "# torch.matmul(torch.rand(3, 2), torch.rand(3, 2))\n",
    "\n",
    "# this works\n",
    "torch.matmul(torch.rand(2, 3), torch.rand(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(10, 3), torch.rand(3, 5)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Numerical Operations - sum, min, max, arg, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) torch.int64\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(9)\n",
      "tensor(90)\n",
      "tensor(45.) tensor(45.)\n",
      "tensor(450) tensor(450)\n"
     ]
    }
   ],
   "source": [
    "# Find the mean - note: torch.mean() function requires a tensor of float\n",
    "x = torch.arange(0, 100, 10)\n",
    "print(x, x.dtype)\n",
    "print(x.argmin()) # this is the index value\n",
    "print(x[0]) # this is the actual numerical value\n",
    "print(x.argmax())\n",
    "print(x[x.argmax()])\n",
    "\n",
    "# make sure to change data type so it is compatible\n",
    "# the mean function only operates on floating points or complext dtypes\n",
    "# x.dtype is int64 before we convert it to float32\n",
    "mean1, mean2 = torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()\n",
    "print(mean1, mean2)\n",
    "print(x.sum(), torch.sum(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, Squeezing and Unsqueezing Tensors\n",
    "\n",
    "##### Manipulate Tensors to shape them in some certain way\n",
    "\n",
    "* Reshaping - reshapes an input tensor to defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory\n",
    "* Stacking - Combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - Removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - Add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " torch.Size([9]),\n",
       " torch.float32,\n",
       " 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor shape issues!\n",
    "\n",
    "# create tensor\n",
    "# re-importing allows us to use torch from this cell (not run the cells above)\n",
    "import torch\n",
    "x = torch.arange(1.0, 10.0)\n",
    "x, x.shape, x.dtype, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]) torch.Size([1, 9]) 2\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]]) torch.Size([9, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "# reshaping needs to be compatible with the original tensor we are reshaping\n",
    "\n",
    "x_reshaped_1 = x.reshape(1, 9) # row=1, col=9\n",
    "print(x_reshaped_1, x_reshaped_1.shape, x_reshaped_1.ndim)\n",
    "\n",
    "x_reshaped_2 = x.reshape(9, 1) # row=9, col=1\n",
    "print(x_reshaped_2, x_reshaped_2.shape, x_reshaped_2.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]]) torch.Size([5, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "x_1 = torch.arange(1.0, 11.0)\n",
    "x_reshaped_3 = x_1.reshape(5, 2) # row=5, col=2\n",
    "print(x_reshaped_3, x_reshaped_3.shape, x_reshaped_3.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Original: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "This is y (no change in dimension: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "This is the view through 'z': (tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))\n",
      "Both z and x values change: (tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))\n",
      "Final z: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Final x: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Final y: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Change the view\n",
    "x = torch.arange(1.0, 10.0)\n",
    "print(f\"This is Original: {x}\")\n",
    "\n",
    "# we are changin the view to (1, 9)\n",
    "# so viewing through 'z' will be a 2 dimensional tensor\n",
    "z = x.view(1, 9)\n",
    "y = x.view(9) # now 'y' also shares the same memory address\n",
    "print(f\"This is y (no change in dimension: {y}\")\n",
    "print(f\"This is the view through 'z': {z, z.shape}\")\n",
    "\n",
    "# \"view\" enables z to share the same memory location as x\n",
    "# changing z changes x because view of a tensor shares the same memory as the original variable\n",
    "# the view of z will stay the same, but the value in the memory will change for all the variables that share the same memory address\n",
    "\n",
    "z[:, 0] = 5 # change first element of z to 5\n",
    "print(f\"Both z and x values change: {z, x}\") # will also change x since they share the same memory location, but different dimension\n",
    "print(f\"Final z: {z}\")\n",
    "print(f\"Final x: {x}\")\n",
    "print(f\"Final y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [8., 8., 8., 8.],\n",
      "        [9., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# Stack tensors on top of each other - concatenation\n",
    "x_stacked_ver = torch.stack([x, x, x, x], dim=0) # dimension of stacking (row, col = 0, 1)\n",
    "x_stacked_hor = torch.stack([x, x, x, x], dim=1) # re-arranges for horizontal stacking\n",
    "print(x_stacked_ver)\n",
    "print(x_stacked_hor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "torch.Size([1, 9])\n",
      "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() - remove all single dimensions from a target tensor\n",
    "# z = reshaped version of x\n",
    "print(z)\n",
    "print(z.shape)\n",
    "print(z.squeeze()) # doesn't modify the original z\n",
    "print(z.squeeze().shape) # reduced dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds single dimension to a target tensor at a specific dim\n",
    "z_squeezed = z.squeeze()\n",
    "print(f\"Previous target: {z_squeezed}\")\n",
    "print(f\"Previous shape: {z_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dimension with unsqueeze\n",
    "z_unsqueezed_0 = z_squeezed.unsqueeze(dim=0)\n",
    "z_unsqueezed_1 = z_squeezed.unsqueeze(dim=1)\n",
    "print(f\"New tensor: {z_unsqueezed_0}\")\n",
    "print(f\"New shape: {z_unsqueezed_0.shape}\")\n",
    "# print(f\"New tensor: {z_unsqueezed_1}\")\n",
    "# print(f\"New shape: {z_unsqueezed_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: torch.Size([224, 224, 3])\n",
      "Permutated Shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearragnes the dimensions of a target tensor in a specified order\n",
    "# useful to apply to images in which there are 3 dimensions (width, height, color channels)\n",
    "# important part deep learning is to turn the data into numerical representation\n",
    "\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color_channels]\n",
    "\n",
    "# Permute the original tensor to rearrange the dim order\n",
    "# uses indices when rearranging\n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "\n",
    "print(f\"Original Shape: {x_original.shape}\")\n",
    "print(f\"Permutated Shape: {x_permuted.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3) # 3 dimensional\n",
    "print(x, x.shape)\n",
    "\n",
    "# index on the first dimension (dim=0)\n",
    "print(x[0])\n",
    "\n",
    "# index on the middle bracket (dim=1)\n",
    "print(x[0][0])\n",
    "\n",
    "# index on most inner bracket (dim=2)\n",
    "print(x[0][0][0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific python numerical computing library.\n",
    "And because of this, PyTorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, wnat in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "tensor([1., 2., 3., 4., 5., 6., 7.]) torch.float32\n",
      "\n",
      "[2. 3. 4. 5. 6. 7. 8.] tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# NumPy Array to Tensor\n",
    "\n",
    "array = np.arange(1.0, 8.0) # dtype = float64\n",
    "tensor = torch.from_numpy(array) # dtype = float64\n",
    "print(array, tensor)\n",
    "\n",
    "# be aware of dtype\n",
    "# numpy default data type = float64\n",
    "# pytorch default data type = float32\n",
    "\n",
    "# change dtype\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "print(tensor, tensor.dtype)\n",
    "print()\n",
    "\n",
    "# change value of array. does it affect tensor?\n",
    "tensor = torch.from_numpy(array)\n",
    "array = array + 1 # add scalar value to each element\n",
    "print(array, tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.]) torch.float32\n",
      "[1. 1. 1. 1. 1. 1. 1.] float32\n"
     ]
    }
   ],
   "source": [
    "# Tensor to NumPy\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "print(tensor, tensor.dtype)\n",
    "print(numpy_tensor, numpy_tensor.dtype) # reflects original data type of torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f634c23ce7422fd6b11ecdff7f8edbe5fc66b9537d5808e3f7994f6ea62867eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
